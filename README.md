# ðŸ“¸ AI Image Captioner

A hybrid image captioning system that leverages local computer vision (BLIP) and cloud-based Large Language Models (Gemini) to transform visual data into rich, cinematic narratives.


## Features

* **Dual-Layer Pipeline:**
* **Interactive UI:**
* **Performance Evaluation:**
* **Cloud Integration:**
* **Robust Architecture:**

## Technologies Used

* **Python 3.12+**
* **HuggingFace Transformers:** BLIP model for visual feature extraction.
* **Google Generative AI:** Gemini-2.0-flash for natural language processing.
* **PyTorch:** Backend for local AI inference.
* **Streamlit:** For the web-based user interface.
* **Pandas / Matplotlib / Seaborn:** For data analysis and visualization.

## Project Structure

```text
image-captioning/
â”œâ”€â”€ src
    â”œâ”€â”€ api/
    |   â””â”€â”€ __init__.py 
    â”‚   â””â”€â”€ gui.py            
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ caption.py
    â”‚   â”œâ”€â”€ enhancer.py
    â”‚   â””â”€â”€ errors.py
â”œâ”€â”€ main.py
â”œâ”€â”€ examples/             # Dataset for evaluation and testing
â”œâ”€â”€ tests/                # Unit tests for core components
â”œâ”€â”€ .env                  # Environment variables (API Keys)
â”œâ”€â”€ requirements.txt      # Project dependencies
â””â”€â”€ README.md             # Project documentation
â””â”€â”€ INSTALL.md            # Install guide
```

## Installation
    For detailed setup instructions and environment configuration, please refer to INSTALL.md.
